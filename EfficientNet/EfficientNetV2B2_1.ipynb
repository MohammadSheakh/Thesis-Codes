{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46acbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2B2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Paths to the dataset\n",
    "labeled_images_folder = 'D:/New CX/CXR8/images/Dest'\n",
    "labels_csv = 'D:/New CX/CXR8/Data_Entry_2017_v2020.csv'\n",
    "\n",
    "# Load the labels CSV file\n",
    "df = pd.read_csv(labels_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de645df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter the dataframe for the diseases of interest\n",
    "diseases = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule',\n",
    "            'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',\n",
    "            'Hernia', 'Pleural_Thickening', 'No Finding']\n",
    "\n",
    "# Create a new column for single-label classification\n",
    "df['Finding Labels'] = df['Finding Labels'].apply(lambda x: x.split('|')[0] if '|' in x else x)\n",
    "\n",
    "# Filter for the diseases of interest\n",
    "df = df[df['Finding Labels'].isin(diseases)]\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Finding Labels'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.67, stratify=temp_df['Finding Labels'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0354f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78484 validated image filenames belonging to 15 classes.\n",
      "Found 11099 validated image filenames belonging to 15 classes.\n",
      "Found 22537 validated image filenames belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data generators with augmentation for training, validation, and testing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow from dataframe for training, validation, and testing generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(192, 192),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(192, 192),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(192, 192),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a088f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a01ca1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Load pre-trained EfficientNetV2B2\n",
    "base_model = EfficientNetV2B2(weights='imagenet', include_top=False, input_shape=(192, 192, 3))\n",
    "\n",
    "# Unfreeze more layers in the base model for fine-tuning\n",
    "for layer in base_model.layers[-100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)  # Added BatchNormalization\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # Added BatchNormalization\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(diseases), activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Learning rate scheduler function\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# Compile the model using Adam optimizer with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate reduction and early stopping callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.00001, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "lr_scheduler = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90542d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2453/2453 [==============================] - 2022s 818ms/step - loss: 2.5868 - accuracy: 0.3614 - val_loss: 1.9269 - val_accuracy: 0.5383 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "2453/2453 [==============================] - 2002s 816ms/step - loss: 1.8688 - accuracy: 0.5131 - val_loss: 1.7452 - val_accuracy: 0.5383 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "2453/2453 [==============================] - 2007s 818ms/step - loss: 1.7787 - accuracy: 0.5241 - val_loss: 1.6134 - val_accuracy: 0.5420 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "2453/2453 [==============================] - 2063s 841ms/step - loss: 1.7163 - accuracy: 0.5296 - val_loss: 1.6516 - val_accuracy: 0.5384 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "2453/2453 [==============================] - 2015s 821ms/step - loss: 1.6873 - accuracy: 0.5302 - val_loss: 1.5629 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "2453/2453 [==============================] - 2016s 822ms/step - loss: 1.6597 - accuracy: 0.5329 - val_loss: 1.7626 - val_accuracy: 0.5383 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "2453/2453 [==============================] - 2019s 823ms/step - loss: 1.6255 - accuracy: 0.5356 - val_loss: 1.5495 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "2453/2453 [==============================] - 2019s 823ms/step - loss: 1.6095 - accuracy: 0.5369 - val_loss: 1.7019 - val_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "2453/2453 [==============================] - 2020s 823ms/step - loss: 1.5762 - accuracy: 0.5384 - val_loss: 1.8015 - val_accuracy: 0.5383 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "2453/2453 [==============================] - 2010s 819ms/step - loss: 1.5527 - accuracy: 0.5410 - val_loss: 1.5183 - val_accuracy: 0.5489 - lr: 1.0000e-04\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model with increased epochs and callbacks\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m, in \u001b[0;36mlr_scheduler\u001b[1;34m(epoch, lr)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lr\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lr \u001b[38;5;241m*\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model with increased epochs and callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[reduce_lr, early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2c635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2453/2453 [==============================] - 2022s 818ms/step - loss: 2.5868 - accuracy: 0.3614 - val_loss: 1.9269 - val_accuracy: 0.5383 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "2453/2453 [==============================] - 2002s 816ms/step - loss: 1.8688 - accuracy: 0.5131 - val_loss: 1.7452 - val_accuracy: 0.5383 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "2453/2453 [==============================] - 2007s 818ms/step - loss: 1.7787 - accuracy: 0.5241 - val_loss: 1.6134 - val_accuracy: 0.5420 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "2453/2453 [==============================] - 2063s 841ms/step - loss: 1.7163 - accuracy: 0.5296 - val_loss: 1.6516 - val_accuracy: 0.5384 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "2453/2453 [==============================] - 2015s 821ms/step - loss: 1.6873 - accuracy: 0.5302 - val_loss: 1.5629 - val_accuracy: 0.5405 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "2453/2453 [==============================] - 2016s 822ms/step - loss: 1.6597 - accuracy: 0.5329 - val_loss: 1.7626 - val_accuracy: 0.5383 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "2453/2453 [==============================] - 2019s 823ms/step - loss: 1.6255 - accuracy: 0.5356 - val_loss: 1.5495 - val_accuracy: 0.5419 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "2453/2453 [==============================] - 2019s 823ms/step - loss: 1.6095 - accuracy: 0.5369 - val_loss: 1.7019 - val_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "2453/2453 [==============================] - 2020s 823ms/step - loss: 1.5762 - accuracy: 0.5384 - val_loss: 1.8015 - val_accuracy: 0.5383 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "2453/2453 [==============================] - 2010s 819ms/step - loss: 1.5527 - accuracy: 0.5410 - val_loss: 1.5183 - val_accuracy: 0.5489 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model with increased epochs and callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[reduce_lr, early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32169c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Predict on the test set\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator)\n",
    "true_labels = test_generator.classes\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "true_labels = [class_labels[i] for i in true_labels]\n",
    "predicted_labels = [class_labels[i] for i in predicted_labels]\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
