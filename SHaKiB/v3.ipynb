{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scans found: 112120 , Total Headers 112120\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "all_xray_df = pd.read_csv(\"E:/A__CVPR/Dataset/bbox/Data_Entry_2017.csv\")\n",
    "all_image_paths = {os.path.basename(x): x for x in glob(os.path.join('D:/New CX/CXR8/images', '*.png'))}\n",
    "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Labels (14): ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n"
     ]
    }
   ],
   "source": [
    "label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\n",
    "all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x) > 0]\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
    "for c_label in all_labels:\n",
    "    if len(c_label) > 1:\n",
    "        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Labels (13) [('Atelectasis', 11559), ('Cardiomegaly', 2776), ('Consolidation', 4667), ('Edema', 2303), ('Effusion', 13317), ('Emphysema', 2516), ('Fibrosis', 1686), ('Infiltration', 19894), ('Mass', 5782), ('Nodule', 6331), ('Pleural_Thickening', 3385), ('Pneumonia', 1431), ('Pneumothorax', 5302)]\n"
     ]
    }
   ],
   "source": [
    "MIN_CASES = 1000\n",
    "all_labels = [c_label for c_label in all_labels if all_xray_df[c_label].sum() > MIN_CASES]\n",
    "print('Clean Labels ({})'.format(len(all_labels)), [(c_label, int(all_xray_df[c_label].sum())) for c_label in all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x) > 0 else 0).values + 4e-2\n",
    "sample_weights /= sample_weights.sum()\n",
    "all_xray_df = all_xray_df.sample(40000, weights=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 30000 validation 10000\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = train_test_split(all_xray_df, test_size=0.25, random_state=2018, stratify=all_xray_df['Finding Labels'].map(lambda x: x[:4]))\n",
    "print('train', train_df.shape[0], 'validation', valid_df.shape[0])\n",
    "valid_df['newLabel'] = valid_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\n",
    "train_df['newLabel'] = train_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_idg = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True, horizontal_flip=True, vertical_flip=False, height_shift_range=0.05, width_shift_range=0.1, rotation_range=5, shear_range=0.1, fill_mode='reflect', zoom_range=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"{}_weights.best.hdf5\".format('xray_class')\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model creation function\n",
    "def MakeModel(IMG_SIZE, bs, channels=1):\n",
    "    model = Sequential()\n",
    "    base_mobilenet_model = MobileNet(input_shape=(*IMG_SIZE, channels), include_top=False, weights=None)\n",
    "    model.add(base_mobilenet_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(all_labels), activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE_LIST = [(1024, 1024), (512, 512), (256, 256), (224, 224), (192, 192), (128, 128), (64, 64)]\n",
    "BATCH_SIZE_LIST = [4, 8, 16, 32, 32, 32, 64]\n",
    "STEPS_PER_EPOCH = 10000\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class AdamAccumulate(Adam):\n",
    "    def __init__(self, lr=0.001, accum_iters=1, **kwargs):\n",
    "        super(AdamAccumulate, self).__init__(learning_rate=lr, **kwargs)\n",
    "        self.accum_iters = accum_iters\n",
    "        self.iterations = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
    "        self.accum_grads = None\n",
    "\n",
    "    def apply_gradients(self, grads_and_vars, name=None, experimental_aggregate_gradients=True):\n",
    "        if self.accum_grads is None:\n",
    "            self.accum_grads = [tf.Variable(tf.zeros_like(var), trainable=False) for grad, var in grads_and_vars]\n",
    "\n",
    "        for (grad, var), accum_grad in zip(grads_and_vars, self.accum_grads):\n",
    "            accum_grad.assign_add(grad)\n",
    "\n",
    "        self.iterations.assign_add(1)\n",
    "\n",
    "        def apply_accumulated_grads():\n",
    "            apply_grads = [(accum_grad / tf.cast(self.accum_iters, tf.float32), var) for accum_grad, (grad, var) in zip(self.accum_grads, grads_and_vars)]\n",
    "            super(AdamAccumulate, self).apply_gradients(apply_grads, name, experimental_aggregate_gradients)\n",
    "            for accum_grad in self.accum_grads:\n",
    "                accum_grad.assign(tf.zeros_like(accum_grad))\n",
    "\n",
    "        tf.cond(tf.equal(self.iterations % self.accum_iters, 0), apply_accumulated_grads, lambda: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28308 validated image filenames belonging to 13 classes.\n",
      "Found 9438 validated image filenames belonging to 13 classes.\n",
      "Running Image Size: (1024, 1024) Running Batch size: 4 Learning Rate: 0.0005\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node 'mod' defined at (most recent call last):\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Mohammad Sheakh\\AppData\\Local\\Temp\\ipykernel_13488\\752811114.py\", line 28, in <module>\n      history = multi_disease_model.fit(train_gen, steps_per_epoch=STEPS_PER_EPOCH, validation_data=valid_gen, epochs=EPOCHS, callbacks=callbacks_list, validation_steps=1000)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n    File \"C:\\Users\\Mohammad Sheakh\\AppData\\Local\\Temp\\ipykernel_13488\\3721505913.py\", line 26, in apply_gradients\n      tf.cond(tf.equal(self.iterations % self.accum_iters, 0), apply_accumulated_grads, lambda: None)\nNode: 'mod'\nJIT compilation failed.\n\t [[{{node mod}}]] [Op:__inference_train_function_60538]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m multi_disease_model \u001b[38;5;241m=\u001b[39m MakeModel(imageSize, batchSize)\n\u001b[0;32m     26\u001b[0m multi_disease_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_disease_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     32\u001b[0m p \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'mod' defined at (most recent call last):\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Mohammad Sheakh\\AppData\\Local\\Temp\\ipykernel_13488\\752811114.py\", line 28, in <module>\n      history = multi_disease_model.fit(train_gen, steps_per_epoch=STEPS_PER_EPOCH, validation_data=valid_gen, epochs=EPOCHS, callbacks=callbacks_list, validation_steps=1000)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 579, in minimize\n    File \"C:\\Users\\Mohammad Sheakh\\AppData\\Local\\Temp\\ipykernel_13488\\3721505913.py\", line 26, in apply_gradients\n      tf.cond(tf.equal(self.iterations % self.accum_iters, 0), apply_accumulated_grads, lambda: None)\nNode: 'mod'\nJIT compilation failed.\n\t [[{{node mod}}]] [Op:__inference_train_function_60538]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "run_this_code = True\n",
    "if run_this_code:\n",
    "    train_results = defaultdict(dict)\n",
    "    test_results = defaultdict(dict)\n",
    "    \n",
    "    lr = 0.0005\n",
    "    syntheticBatch = 256\n",
    "    \n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    for imageSize, batchSize in zip(IMG_SIZE_LIST, BATCH_SIZE_LIST):\n",
    "        batch = int(256 / batchSize)\n",
    "        \n",
    "        train_gen = core_idg.flow_from_dataframe(dataframe=train_df, directory=None, x_col='path', y_col='newLabel', class_mode='categorical', classes=all_labels, target_size=imageSize, color_mode='grayscale', batch_size=batchSize)\n",
    "        valid_gen = core_idg.flow_from_dataframe(dataframe=valid_df, directory=None, x_col='path', y_col='newLabel', class_mode='categorical', classes=all_labels, target_size=imageSize, color_mode='grayscale', batch_size=batchSize)\n",
    "\n",
    "        print('Running Image Size:', imageSize, 'Running Batch size:', batchSize, 'Learning Rate:', lr)\n",
    "        \n",
    "        predictions_train = pd.DataFrame()\n",
    "        predictions_test = pd.DataFrame()\n",
    "\n",
    "        opt = AdamAccumulate(lr=lr, accum_iters=batch)\n",
    "        \n",
    "        multi_disease_model = MakeModel(imageSize, batchSize)\n",
    "        multi_disease_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['binary_accuracy', 'mae'])\n",
    "\n",
    "        history = multi_disease_model.fit(train_gen, steps_per_epoch=STEPS_PER_EPOCH, validation_data=valid_gen, epochs=EPOCHS, callbacks=callbacks_list, validation_steps=1000)\n",
    "\n",
    "        plt.plot(history.history['val_loss'])\n",
    "\n",
    "        p = history.history['val_loss'][0]\n",
    "\n",
    "        del multi_disease_model, history\n",
    "        gc.collect()\n",
    "        print('*' * 50)\n",
    "        print('')\n",
    "\n",
    "        test_results[imageSize[0]][lr] = p\n",
    "        imageSizeFile = pd.DataFrame(test_results)\n",
    "        imageSizeFile.to_csv(\"imageSize.csv\", index=True)\n",
    "\n",
    "    plt.legend([str(x[0]) for x in IMG_SIZE_LIST], loc='upper right')\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    plt.savefig('image_size_selection.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheakh310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
