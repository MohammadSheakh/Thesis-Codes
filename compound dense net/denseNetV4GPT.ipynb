{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the dataset\n",
    "labeled_images_folder = 'D:/New CX/CXR8/images/Dest'  # Adjust this to the actual folder where your images are stored\n",
    "labels_csv = 'D:/New CX/CXR8/Data_Entry_2017_v2020.csv'  # Path to the CSV file containing labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels CSV file\n",
    "df = pd.read_csv(labels_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for the diseases of interest\n",
    "diseases = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule',\n",
    "            'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',\n",
    "            'Hernia', 'Pleural_Thickening', 'No Finding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for single-label classification\n",
    "df['Finding Labels'] = df['Finding Labels'].apply(lambda x: x.split('|')[0] if '|' in x else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter for the diseases of interest\n",
    "df = df[df['Finding Labels'].isin(diseases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the number of images for each disease class\n",
    "disease_counts = df['Finding Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Finding Labels'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.67, stratify=temp_df['Finding Labels'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the distribution of the datasets\n",
    "print(f\"Training set: {train_df.shape[0]} samples\")\n",
    "print(f\"Validation set: {val_df.shape[0]} samples\")\n",
    "print(f\"Testing set: {test_df.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators with augmentation for training, validation, and testing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flow from dataframe for training, validation, and testing generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important to keep the order for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained DenseNet121\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(diseases), activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model using SGD with a lower learning rate\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate reduction callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.00001, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with increased epochs and callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=50,  # Increase epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[reduce_lr]  # Add reduce_lr callback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator)\n",
    "true_labels = test_generator.classes\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "true_labels = [class_labels[i] for i in true_labels]\n",
    "predicted_labels = [class_labels[i] for i in predicted_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving higher accuracy in medical image classification tasks like the one you're working on requires careful consideration of several factors including data preprocessing, model architecture, hyperparameter tuning, and potentially using more advanced techniques like transfer learning with fine-tuning. Here's a revised approach to potentially improve your model's accuracy:\n",
    "Steps to Improve Accuracy:\n",
    "\n",
    "    Data Augmentation: Enhance the diversity and quantity of your training data by using more aggressive data augmentation techniques. This helps in generalizing better to unseen data.\n",
    "\n",
    "    Transfer Learning with Fine-tuning: Instead of freezing all layers of DenseNet121, consider fine-tuning some of its top layers along with adding additional dense layers to adapt the model to your specific classification task.\n",
    "\n",
    "    Learning Rate Scheduling: Implement learning rate schedules (e.g., reducing learning rate over epochs) to help the model converge better and potentially avoid local minima.\n",
    "\n",
    "    Increase Training Data Size: If feasible, increase the size of your training dataset. More data often leads to better model generalization.\n",
    "\n",
    "    Experiment with Different Architectures: DenseNet121 is a strong architecture, but you could experiment with other pre-trained models like ResNet, EfficientNet, etc., to see if they perform better for your specific task.\n",
    "\n",
    "    Regularization: Apply regularization techniques such as dropout or L2 regularization to prevent overfitting.Achieving higher accuracy in medical image classification tasks like the one you're working on requires careful consideration of several factors including data preprocessing, model architecture, hyperparameter tuning, and potentially using more advanced techniques like transfer learning with fine-tuning. Here's a revised approach to potentially improve your model's accuracy:\n",
    "Steps to Improve Accuracy:\n",
    "\n",
    "    Data Augmentation: Enhance the diversity and quantity of your training data by using more aggressive data augmentation techniques. This helps in generalizing better to unseen data.\n",
    "\n",
    "    Transfer Learning with Fine-tuning: Instead of freezing all layers of DenseNet121, consider fine-tuning some of its top layers along with adding additional dense layers to adapt the model to your specific classification task.\n",
    "\n",
    "    Learning Rate Scheduling: Implement learning rate schedules (e.g., reducing learning rate over epochs) to help the model converge better and potentially avoid local minima.\n",
    "\n",
    "    Increase Training Data Size: If feasible, increase the size of your training dataset. More data often leads to better model generalization.\n",
    "\n",
    "    Experiment with Different Architectures: DenseNet121 is a strong architecture, but you could experiment with other pre-trained models like ResNet, EfficientNet, etc., to see if they perform better for your specific task.\n",
    "\n",
    "    Regularization: Apply regularization techniques such as dropout or L2 regularization to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Modifications:\n",
    "\n",
    "    Data Augmentation: Enhanced data augmentation in the train_datagen to increase the diversity of training images.\n",
    "\n",
    "    Transfer Learning with Fine-tuning: Added a loop to freeze all layers of base_model and unfroze the last few layers for fine-tuning. This step allows the model to adapt better to the specific classification task.\n",
    "\n",
    "    Learning Rate Reduction: Implemented a ReduceLROnPlateau callback to dynamically adjust the learning rate during training, which can help in reaching a better minimum in the loss landscape.\n",
    "\n",
    "    Increased Training Epochs: Increased the number of training epochs to allow the model more time to learn from the augmented data.\n",
    "\n",
    "By incorporating these changes, the model should have a better chance of achieving higher accuracy. Adjust the learning rate (lr), batch size, and other parameters further based on your specific dataset characteristics and computational resources.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THESIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
