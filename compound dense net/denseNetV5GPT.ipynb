{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths to the dataset\n",
    "labeled_images_folder = 'D:/New CX/CXR8/images/Dest'  # Adjust this to the actual folder where your images are stored\n",
    "labels_csv = 'D:/New CX/CXR8/Data_Entry_2017_v2020.csv'  # Path to the CSV file containing labels\n",
    "\n",
    "# Load the labels CSV file\n",
    "df = pd.read_csv(labels_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for the diseases of interest\n",
    "diseases = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule',\n",
    "            'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',\n",
    "            'Hernia', 'Pleural_Thickening', 'No Finding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new column for single-label classification\n",
    "df['Finding Labels'] = df['Finding Labels'].apply(lambda x: x.split('|')[0] if '|' in x else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the diseases of interest\n",
    "df = df[df['Finding Labels'].isin(diseases)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Finding Labels'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.67, stratify=temp_df['Finding Labels'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data generators with augmentation for training, validation, and testing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78484 validated image filenames belonging to 15 classes.\n",
      "Found 11099 validated image filenames belonging to 15 classes.\n",
      "Found 22537 validated image filenames belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flow from dataframe for training, validation, and testing generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(192, 192),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(192, 192),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=labeled_images_folder,\n",
    "    x_col='Image Index',\n",
    "    y_col='Finding Labels',\n",
    "    target_size=(192, 192),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important to keep the order for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained DenseNet121\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(192, 192, 3))\n",
    "\n",
    "# Unfreeze some layers in the base model for fine-tuning\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
    "x = Dense(256, activation='relu')(x) ###################  ################### 512\n",
    "x = Dropout(0.5)(x)  # Adding another dropout layer\n",
    "predictions = Dense(len(diseases), activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# Compile the model using Adam optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate reduction and early stopping callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.00001, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1604/2453 [==================>...........] - ETA: 10:30 - loss: 1.7766 - accuracy: 0.5169"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with increased epochs and callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 338s 958ms/step - loss: 1.5297 - accuracy: 0.5401\n",
      "Test Accuracy: 0.5401340126991272\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 253s 714ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator)\n",
    "true_labels = test_generator.classes\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "true_labels = [class_labels[i] for i in true_labels]\n",
    "predicted_labels = [class_labels[i] for i in predicted_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       Atelectasis       0.29      0.08      0.12      2321\n",
      "      Cardiomegaly       0.50      0.00      0.00       483\n",
      "     Consolidation       0.00      0.00      0.00       669\n",
      "             Edema       0.12      0.00      0.01       375\n",
      "          Effusion       0.28      0.20      0.23      1616\n",
      "         Emphysema       0.35      0.02      0.04       348\n",
      "          Fibrosis       0.00      0.00      0.00       244\n",
      "            Hernia       0.00      0.00      0.00        32\n",
      "      Infiltration       0.28      0.02      0.04      2371\n",
      "              Mass       0.00      0.00      0.00       588\n",
      "        No Finding       0.56      0.96      0.71     12133\n",
      "            Nodule       0.00      0.00      0.00       605\n",
      "Pleural_Thickening       0.00      0.00      0.00       245\n",
      "         Pneumonia       0.00      0.00      0.00        65\n",
      "      Pneumothorax       0.00      0.00      0.00       442\n",
      "\n",
      "          accuracy                           0.54     22537\n",
      "         macro avg       0.16      0.09      0.08     22537\n",
      "      weighted avg       0.40      0.54      0.42     22537\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Application Installed\\anacondaa\\envs\\sheakh310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving higher accuracy in medical image classification tasks like the one you're working on requires careful consideration of several factors including data preprocessing, model architecture, hyperparameter tuning, and potentially using more advanced techniques like transfer learning with fine-tuning. Here's a revised approach to potentially improve your model's accuracy:\n",
    "Steps to Improve Accuracy:\n",
    "\n",
    "    Data Augmentation: Enhance the diversity and quantity of your training data by using more aggressive data augmentation techniques. This helps in generalizing better to unseen data.\n",
    "\n",
    "    Transfer Learning with Fine-tuning: Instead of freezing all layers of DenseNet121, consider fine-tuning some of its top layers along with adding additional dense layers to adapt the model to your specific classification task.\n",
    "\n",
    "    Learning Rate Scheduling: Implement learning rate schedules (e.g., reducing learning rate over epochs) to help the model converge better and potentially avoid local minima.\n",
    "\n",
    "    Increase Training Data Size: If feasible, increase the size of your training dataset. More data often leads to better model generalization.\n",
    "\n",
    "    Experiment with Different Architectures: DenseNet121 is a strong architecture, but you could experiment with other pre-trained models like ResNet, EfficientNet, etc., to see if they perform better for your specific task.\n",
    "\n",
    "    Regularization: Apply regularization techniques such as dropout or L2 regularization to prevent overfitting.Achieving higher accuracy in medical image classification tasks like the one you're working on requires careful consideration of several factors including data preprocessing, model architecture, hyperparameter tuning, and potentially using more advanced techniques like transfer learning with fine-tuning. Here's a revised approach to potentially improve your model's accuracy:\n",
    "Steps to Improve Accuracy:\n",
    "\n",
    "    Data Augmentation: Enhance the diversity and quantity of your training data by using more aggressive data augmentation techniques. This helps in generalizing better to unseen data.\n",
    "\n",
    "    Transfer Learning with Fine-tuning: Instead of freezing all layers of DenseNet121, consider fine-tuning some of its top layers along with adding additional dense layers to adapt the model to your specific classification task.\n",
    "\n",
    "    Learning Rate Scheduling: Implement learning rate schedules (e.g., reducing learning rate over epochs) to help the model converge better and potentially avoid local minima.\n",
    "\n",
    "    Increase Training Data Size: If feasible, increase the size of your training dataset. More data often leads to better model generalization.\n",
    "\n",
    "    Experiment with Different Architectures: DenseNet121 is a strong architecture, but you could experiment with other pre-trained models like ResNet, EfficientNet, etc., to see if they perform better for your specific task.\n",
    "\n",
    "    Regularization: Apply regularization techniques such as dropout or L2 regularization to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Modifications:\n",
    "\n",
    "    Data Augmentation: Enhanced data augmentation in the train_datagen to increase the diversity of training images.\n",
    "\n",
    "    Transfer Learning with Fine-tuning: Added a loop to freeze all layers of base_model and unfroze the last few layers for fine-tuning. This step allows the model to adapt better to the specific classification task.\n",
    "\n",
    "    Learning Rate Reduction: Implemented a ReduceLROnPlateau callback to dynamically adjust the learning rate during training, which can help in reaching a better minimum in the loss landscape.\n",
    "\n",
    "    Increased Training Epochs: Increased the number of training epochs to allow the model more time to learn from the augmented data.\n",
    "\n",
    "By incorporating these changes, the model should have a better chance of achieving higher accuracy. Adjust the learning rate (lr), batch size, and other parameters further based on your specific dataset characteristics and computational resources.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THESIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
